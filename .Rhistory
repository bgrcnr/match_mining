mutate_all(funs(./10 + rnorm(1,.,.*0.1))) %>%
mutate_all(funs(round(.,2))) %>%
mutate(Site = 3)
dat_add
dat <- rbind(dat, dat_add) %>%
mutate(Site = Site - 1)
dat
# Make split index
train_index <- sample(1:nrow(dat), nrow(dat)*0.75)
# Full data set
data_variables <- as.matrix(dat[,-1])
data_label <- dat[,"Site"]
data_matrix <- xgb.DMatrix(data = as.matrix(dat), label = data_label)
# split train data and make xgb.DMatrix
train_data   <- data_variables[train_index,]
train_label  <- data_label[train_index]
train_matrix <- xgb.DMatrix(data = train_data, label = train_label)
# split test data and make xgb.DMatrix
test_data  <- data_variables[-train_index,]
test_label <- data_label[-train_index]
test_matrix <- xgb.DMatrix(data = test_data, label = test_label)
test_matrix
numberOfClasses <- length(unique(dat$Site))
numberOfClasses
xgb_params <- list("objective" = "multi:softprob",
"eval_metric" = "mlogloss",
"num_class" = numberOfClasses)
nround    <- 50 # number of XGBoost rounds
cv.nfold  <- 5
# Fit cv.nfold * cv.nround XGB models and save OOF predictions
cv_model <- xgb.cv(params = xgb_params,
data = train_matrix,
nrounds = nround,
nfold = cv.nfold,
verbose = FALSE,
prediction = TRUE)
OOF_prediction <- data.frame(cv_model$pred) %>%
mutate(max_prob = max.col(., ties.method = "last"),
label = train_label + 1)
OOF_prediction
head(OOF_prediction)
confusionMatrix(factor(OOF_prediction$max_prob),
factor(OOF_prediction$label),
mode = "everything")
# Predict hold-out test set
test_pred <- predict(bst_model, newdata = test_matrix)
test_prediction <- matrix(test_pred, nrow = numberOfClasses,
ncol=length(test_pred)/numberOfClasses) %>%
t() %>%
data.frame() %>%
mutate(label = test_label + 1,
max_prob = max.col(., "last"))
# confusion matrix of test set
confusionMatrix(factor(test_prediction$max_prob),
factor(test_prediction$label),
mode = "everything")
bst_model <- xgb.train(params = xgb_params,
data = train_matrix,
nrounds = nround)
# Predict hold-out test set
test_pred <- predict(bst_model, newdata = test_matrix)
test_prediction <- matrix(test_pred, nrow = numberOfClasses,
ncol=length(test_pred)/numberOfClasses) %>%
t() %>%
data.frame() %>%
mutate(label = test_label + 1,
max_prob = max.col(., "last"))
# confusion matrix of test set
confusionMatrix(factor(test_prediction$max_prob),
factor(test_prediction$label),
mode = "everything")
dat
RBGlass1
require(data.table)
require(lubridate)
require(data.table)
require(anytime)
require(scatterplot3d)
require(FNN)
require(glmnet)
require(TunePareto)
require(data.table)
require(RANN.L1)
require(data.table)
require(anytime)
require(scatterplot3d)
require(FNN)
require(glmnet)
require(TunePareto)
require(data.table)
require(RANN.L1)
require(lubridate)
require(devtools)
#save paths
matches_data_path = "C:/Files/df9b1196-e3cf-4cc7-9159-f236fe738215_matches.rds"
odd_details_data_path = "C:/Files/df9b1196-e3cf-4cc7-9159-f236fe738215_odd_details.rds"
testStart=as.Date('2018-08-16')
trainStart=as.Date('2012-07-15')
rem_miss_threshold=0.01 #parameter for removing bookmaker odds with missing ratio greater than this threshold
source('data_preprocessing.r')
source('feature_extraction.r')
source('performance_metrics.r')
source('train_models.r')
# read data
matches_raw=readRDS(matches_data_path)
odd_details_raw=readRDS(odd_details_data_path)
# preprocess matches
matches=matches_data_preprocessing(matches_raw)
# preprocess odd data
odd_details=details_data_preprocessing(odd_details_raw,matches)
# extract open and close odd type features from multiple bookmakers
features=extract_features.openclose(matches,odd_details,pMissThreshold=rem_miss_threshold,trainStart,testStart)
# divide data based on the provided dates
train_features=features[Match_Date>=trainStart & Match_Date<testStart]
test_features=features[Match_Date>=testStart]
train_features <- train_features[complete.cases(train_features)]
test_features <- test_features[complete.cases(test_features)]
trainclass <- train_features$Match_Result
traindata <- train_features[,c(-1,-2,-3,-7)]
testclass <- test_features$Match_Result
testdata <- test_features[,c(-1,-2,-3,-7)]
trainclass <- (trainclass == "Home")*1 + (trainclass == "Away")*2
testclass <- (testclass == "Home")*1 + (testclass == "Away")*2
cols <- c(3:5,25:30,(ncol(traindata)-3):ncol(traindata))
train1 <- traindata[,..cols]
test1 <- testdata[,..cols]
train1 <- scale(train1)
test1 <- scale(test1)
pred11 <- knn(train1,test1, trainclass, k = 29, prob = TRUE)
table(pred11,testclass)
sum(pred11==testclass)/length(testclass)
length(pred)
length(trainclass)
x <- rbind(train1,test1)
kdist <- KODAMA::knn.dist(x)
pred <- KODAMA::knn.predict(1:nrow(train1), (nrow(train1)+1):nrow(x), trainclass, kdist, k=29, agg.meth = "majority")
# display the confusion matrix
table(pred,testclass)
sum(pred==testclass)/length(testclass)
# view probabilities (all class probabilities are returned)
prob <- KODAMA::knn.probability(1:nrow(train1), (nrow(train1)+1):nrow(x), trainclass, kdist, k=29)
results <- matrix(1:(90*3), 3)
results[1,] <- (testclass == 0)*1
results[2,] <- (testclass == 1)*1
results[3,] <- (testclass == 2)*1
RPS_res <- RPS(prob, results)
RPS_res
########## End of Nearest Neighbor Analysis
require(nnet)
train2 <- traindata[,..cols]
test2 <- testdata[,..cols]
train2$Match_Result <- trainclass
test2$Match_Result <- testclass
multinomModel <- multinom(Match_Result ~ ., data=train2)
summary (multinomModel)
predicted_scores <- predict (multinomModel, test2, "probs") # predict on new data
predicted_class <- predict (multinomModel, test2)
table(predicted_class, testclass)
accuracy <- sum(predicted_class == testclass)/length(testclass)
accuracy
RPS2 <- RPS(t(predicted_scores), results)
RPS2
####### End of Working Multinomial
train3 <- traindata[,..cols]
test3 <- testdata[,..cols]
sample_model <- train_glmnet(train_features,test_features)
sample_model
sample_mat <- results
sample_mat[1,] <- t(sample_model$predictions[,4])
sample_mat[2,] <- t(sample_model$predictions[,3])
sample_mat[3,] <- t(sample_model$predictions[,5])
rps3 <- RPS(sample_mat,results)
#### End of Hoca Model
getwd()
setwd("C:/Users/Bugra/Google Drive/Courses/MS_IE_Boun/IE 582 - Statistical Learning for Data Mining/Project/fall18-instructor-master")
getwd()
source('data_preprocessing.r')
source('feature_extraction.r')
source('performance_metrics.r')
source('train_models.r')
# preprocess matches
matches=matches_data_preprocessing(matches_raw)
# preprocess odd data
odd_details=details_data_preprocessing(odd_details_raw,matches)
# extract open and close odd type features from multiple bookmakers
features=extract_features.openclose(matches,odd_details,pMissThreshold=rem_miss_threshold,trainStart,testStart)
# divide data based on the provided dates
train_features=features[Match_Date>=trainStart & Match_Date<testStart]
test_features=features[Match_Date>=testStart]
train_features <- train_features[complete.cases(train_features)]
test_features <- test_features[complete.cases(test_features)]
trainclass <- train_features$Match_Result
traindata <- train_features[,c(-1,-2,-3,-7)]
testclass <- test_features$Match_Result
testdata <- test_features[,c(-1,-2,-3,-7)]
trainclass <- (trainclass == "Home")*1 + (trainclass == "Away")*2
testclass <- (testclass == "Home")*1 + (testclass == "Away")*2
cols <- c(3:5,25:30,(ncol(traindata)-3):ncol(traindata))
train1 <- traindata[,..cols]
test1 <- testdata[,..cols]
train1 <- scale(train1)
test1 <- scale(test1)
pred11 <- knn(train1,test1, trainclass, k = 29, prob = TRUE)
table(pred11,testclass)
sum(pred11==testclass)/length(testclass)
length(pred)
length(trainclass)
x <- rbind(train1,test1)
kdist <- KODAMA::knn.dist(x)
pred <- KODAMA::knn.predict(1:nrow(train1), (nrow(train1)+1):nrow(x), trainclass, kdist, k=29, agg.meth = "majority")
# display the confusion matrix
table(pred,testclass)
sum(pred==testclass)/length(testclass)
# view probabilities (all class probabilities are returned)
prob <- KODAMA::knn.probability(1:nrow(train1), (nrow(train1)+1):nrow(x), trainclass, kdist, k=29)
results <- matrix(1:(90*3), 3)
results[1,] <- (testclass == 0)*1
results[2,] <- (testclass == 1)*1
results[3,] <- (testclass == 2)*1
RPS_res <- RPS(prob, results)
RPS_res
########## End of Nearest Neighbor Analysis
train4 <- traindata[,..cols]
test4 <- testdata[,..cols]
train4$Match_Result <- trainclass
test4$Match_Result <- testclass
train4
train4 <- as.matrix(train4)
train4
test4 <- as.matrix(test4)
data_variables
data_label
data_matrix
train4 <- traindata[,..cols]
test4 <- testdata[,..cols]
train_matrix <- xgb.DMatrix(data = train4, label = trainclass)
train4 <- as.matrix(train4)
train_matrix <- xgb.DMatrix(data = train4, label = trainclass)
test4 <- as.matrix(test4)
test_matrix <- xgb.DMatrix(data = test4, label = testclass)
test_matrix
numberOfClasses <- length(unique(trainclass))
numberOfClasses
xgb_params <- list("objective" = "multi:softprob",
"eval_metric" = "mlogloss",
"num_class" = numberOfClasses)
nround    <- 50 # number of XGBoost rounds
cv.nfold  <- 5
# Fit cv.nfold * cv.nround XGB models and save OOF predictions
cv_model <- xgb.cv(params = xgb_params,
data = train_matrix,
nrounds = nround,
nfold = cv.nfold,
verbose = FALSE,
prediction = TRUE)
OOF_prediction <- data.frame(cv_model$pred) %>%
mutate(max_prob = max.col(., ties.method = "last"),
label = train_label + 1)
OOF_prediction <- data.frame(cv_model$pred) %>%
mutate(max_prob = max.col(., ties.method = "last"),
label = trainclass + 1)
OOF_prediction <- data.frame(cv_model$pred) %>%
mutate(max_prob = max.col(., ties.method = "last"),
label = trainclass)
head(OOF_prediction)
confusionMatrix(factor(OOF_prediction$max_prob),
factor(OOF_prediction$label),
mode = "everything")
OOF_prediction <- data.frame(cv_model$pred) %>%
mutate(max_prob = max.col(., ties.method = "last"),
label = trainclass + 1)
confusionMatrix(factor(OOF_prediction$max_prob),
factor(OOF_prediction$label),
mode = "everything")
bst_model <- xgb.train(params = xgb_params,
data = train_matrix,
nrounds = nround)
test_pred <- predict(bst_model, newdata = test_matrix)
test_prediction <- matrix(test_pred, nrow = numberOfClasses,
ncol=length(test_pred)/numberOfClasses) %>%
t() %>%
data.frame() %>%
mutate(label = test_label + 1,
max_prob = max.col(., "last"))
test_prediction <- matrix(test_pred, nrow = numberOfClasses,
ncol=length(test_pred)/numberOfClasses) %>%
t() %>%
data.frame() %>%
mutate(label = testclass + 1,
max_prob = max.col(., "last"))
# confusion matrix of test set
confusionMatrix(factor(test_prediction$max_prob),
factor(test_prediction$label),
mode = "everything")
test_prediction$max_prob
install.packages("adabag")
require(adabag)
## rpart library should be loaded
data(iris)
iris
iris.adaboost <- boosting(Species~., data=iris, boos=TRUE,
mfinal=3)
importanceplot(iris.adaboost)
sub <- c(sample(1:50, 35), sample(51:100, 35), sample(101:150, 35))
sub
iris.bagging <- bagging(Species ~ ., data=iris[sub,], mfinal=3)
#Predicting with labeled data
iris.predbagging<-predict.bagging(iris.bagging, newdata=iris[-sub,])
iris.predbagging
#Predicting with unlabeled data
iris.predbagging<- predict.bagging(iris.bagging, newdata=iris[-sub,-5])
iris.predbagging
train2 <- traindata[,..cols]
test2 <- testdata[,..cols]
train2$Match_Result <- trainclass
test2$Match_Result <- testclass
match.bagging <- baggind(Match_Result ~ ., data = train2, mfinal = 10)
match.bagging <- bagging(Match_Result ~ ., data = train2, mfinal = 10)
train2
match.bagging <- bagging(Match_Result ~ ., data = train2)
match.bagging <- bagging(Match_Result ~ ., data = train2, mfinal = 5)
match.bagging <- bagging(Match_Result ~ ., data = train2, mfinal = 3)
match.bagging <- bagging(Match_Result ~ ., data = train2, mfinal = 1)
match.bagging <- bagging(Match_Result ~ ., data = train2, mfinal = 24)
train2$Match_Result <- as.factor(trainclass)
test2$Match_Result <- as.factor(testclass)
match.bagging <- bagging(Match_Result ~ ., data = train2, boos = TRUE, mfinal = 10, control = (minsplit = 0))
match.predbegging <- predict.bagging(match.bagging, newdata = test2)
match.predbegging
train4 <- traindata[,..cols]
test4 <- testdata[,..cols]
train4$Match_Result <- as.factor(trainclass)
test4$Match_Result <- as.factor(testclass)
match.bagging <- bagging(Match_Result ~ ., data = train4, boos = TRUE, mfinal = 10, control = (minsplit = 0))
match.predbegging <- predict.bagging(match.bagging, newdata = test4)
match.predbegging$prob
boosting_probs <- t(match.predbegging$prob)
boosting_probs
rps4 <- RPS(boosting_probs,results)
rps4
rps4
match.predbegging$confusion
match.predbegging
match.predbegging$confusion
55/90
rps4
train_features
RPS_res
avgrps1 <- RPS_res/length(testclass)
avgrps1
avgrps1
avgrps2 <- RPS2/length(testclass)
avgrps2
avgrps3 <- rps3/length(testclass)
avgrps3
rps3 <- RPS(sample_mat,results)
train3 <- traindata[,..cols]
test3 <- testdata[,..cols]
require(nnet)
cols <- c(3:5,25:30,(ncol(traindata)-3):ncol(traindata))
train2 <- traindata[,..cols]
require(data.table)
require(anytime)
require(scatterplot3d)
require(FNN)
require(glmnet)
require(TunePareto)
require(data.table)
require(RANN.L1)
require(lubridate)
require(devtools)
source('data_preprocessing.r')
source('feature_extraction.r')
source('performance_metrics.r')
source('train_models.r')
rm(list=ls())
gc()
matches_data_path = "C:/Files/df9b1196-e3cf-4cc7-9159-f236fe738215_matches.rds"
odd_details_data_path = "C:/Files/df9b1196-e3cf-4cc7-9159-f236fe738215_odd_details.rds"
testStart=as.Date('2018-08-16')
trainStart=as.Date('2012-07-15')
rem_miss_threshold=0.01 #parameter for removing bookmaker odds with missing ratio greater than this threshold
source('data_preprocessing.r')
source('feature_extraction.r')
source('performance_metrics.r')
source('train_models.r')
# read data
matches_raw=readRDS(matches_data_path)
odd_details_raw=readRDS(odd_details_data_path)
# preprocess matches
matches=matches_data_preprocessing(matches_raw)
# preprocess odd data
odd_details=details_data_preprocessing(odd_details_raw,matches)
# extract open and close odd type features from multiple bookmakers
features=extract_features.openclose(matches,odd_details,pMissThreshold=rem_miss_threshold,trainStart,testStart)
# divide data based on the provided dates
train_features=features[Match_Date>=trainStart & Match_Date<testStart]
test_features=features[Match_Date>=testStart]
train_features <- train_features[complete.cases(train_features)]
test_features <- test_features[complete.cases(test_features)]
trainclass <- train_features$Match_Result
traindata <- train_features[,c(-1,-2,-3,-7)]
testclass <- test_features$Match_Result
testdata <- test_features[,c(-1,-2,-3,-7)]
trainclass <- (trainclass == "Home")*1 + (trainclass == "Away")*2
testclass <- (testclass == "Home")*1 + (testclass == "Away")*2
cols <- c(3:5,25:30,(ncol(traindata)-3):ncol(traindata))
train1 <- traindata[,..cols]
test1 <- testdata[,..cols]
train1 <- scale(train1)
test1 <- scale(test1)
pred11 <- knn(train1,test1, trainclass, k = 29, prob = TRUE)
table(pred11,testclass)
sum(pred11==testclass)/length(testclass)
length(pred)
length(trainclass)
x <- rbind(train1,test1)
kdist <- KODAMA::knn.dist(x)
pred <- KODAMA::knn.predict(1:nrow(train1), (nrow(train1)+1):nrow(x), trainclass, kdist, k=29, agg.meth = "majority")
# display the confusion matrix
table(pred,testclass)
sum(pred==testclass)/length(testclass)
# view probabilities (all class probabilities are returned)
prob <- KODAMA::knn.probability(1:nrow(train1), (nrow(train1)+1):nrow(x), trainclass, kdist, k=29)
results <- matrix(1:(90*3), 3)
results[1,] <- (testclass == 0)*1
results[2,] <- (testclass == 1)*1
results[3,] <- (testclass == 2)*1
RPS_res <- RPS(prob, results)
RPS_res
avgrps1 <- RPS_res/length(testclass)
avgrps1
########## End of Nearest Neighbor Analysis
require(nnet)
train2 <- traindata[,..cols]
test2 <- testdata[,..cols]
train2$Match_Result <- trainclass
test2$Match_Result <- testclass
multinomModel <- multinom(Match_Result ~ ., data=train2)
summary (multinomModel)
predicted_scores <- predict (multinomModel, test2, "probs") # predict on new data
predicted_class <- predict (multinomModel, test2)
table(predicted_class, testclass)
accuracy <- sum(predicted_class == testclass)/length(testclass)
accuracy
RPS2 <- RPS(t(predicted_scores), results)
RPS2
avgrps2 <- RPS2/length(testclass)
avgrps2
####### End of Working Multinomial
train3 <- traindata[,..cols]
test3 <- testdata[,..cols]
sample_model <- train_glmnet(train_features,test_features)
sample_model
sample_mat <- results
sample_mat[1,] <- t(sample_model$predictions[,4])
sample_mat[2,] <- t(sample_model$predictions[,3])
sample_mat[3,] <- t(sample_model$predictions[,5])
rps3 <- RPS(sample_mat,results)
avgrps3 <- rps3/length(testclass)
avgrps3
#### End of Hoca Model
#### boosting
train4 <- traindata[,..cols]
test4 <- testdata[,..cols]
train4$Match_Result <- as.factor(trainclass)
test4$Match_Result <- as.factor(testclass)
match.bagging <- bagging(Match_Result ~ ., data = train4, boos = TRUE, mfinal = 10, control = (minsplit = 0))
match.predbegging <- predict.bagging(match.bagging, newdata = test4)
boosting_probs <- t(match.predbegging$prob)
rps4 <- RPS(boosting_probs,results)
rps4
library("xgboost")  # the main algorithm
library("archdata") # for the sample dataset
library("caret")    # for the confusionmatrix() function (also needs e1071 package)
library("dplyr")    # for some data preperation
library("Ckmeans.1d.dp") # for xgb.ggplot.importance
train4 <- traindata[,..cols]
test4 <- testdata[,..cols]
train4$Match_Result <- as.factor(trainclass)
test4$Match_Result <- as.factor(testclass)
match.bagging <- bagging(Match_Result ~ ., data = train4, boos = TRUE, mfinal = 10, control = (minsplit = 0))
#### boosting
library("xgboost")  # the main algorithm
#### boosting
library(adabag)  # the main algorithm
train4 <- traindata[,..cols]
test4 <- testdata[,..cols]
train4$Match_Result <- as.factor(trainclass)
test4$Match_Result <- as.factor(testclass)
match.bagging <- bagging(Match_Result ~ ., data = train4, boos = TRUE, mfinal = 10, control = (minsplit = 0))
match.predbegging <- predict.bagging(match.bagging, newdata = test4)
boosting_probs <- t(match.predbegging$prob)
rps4 <- RPS(boosting_probs,results)
rps4
avgrps4 <- rps4/length(testclass)
avgrps4
rps1mat <- RPS_matrix(prob,results)
rps1mat
rps2mat <- RPS_matrix(t(predicted_scores), results)
rps2mat
rps3mat <- RPS_matrix(sample_mat,results)
rps3mat
rps4mat <- RPS_matrix(boosting_probs,results)
rps4mat
rps1mat
rps2mat
rps3mat
rps4mat
RPS_matrix(boosting_probs,results)
sample_model
avgrps3
